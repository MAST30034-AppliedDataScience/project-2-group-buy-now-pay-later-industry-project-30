{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Manager\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"7g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .appName('exploration') \\\n",
    "    .getOrCreate()\n",
    "# spark.conf.set(\"spark.sql.session.timeZone\", \"America/New_York\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions1 = spark.read.parquet(\"../data/transactions/transactions_20210228_20210827_snapshot\")\n",
    "transactions2 = spark.read.parquet(\"../data/transactions/transactions_20210828_20220227_snapshot\")\n",
    "transactions3 = spark.read.parquet(\"../data/transactions/transactions_20220228_20220828_snapshot\")\n",
    "\n",
    "transactions = transactions1.union(transactions2).union(transactions3)\n",
    "# transactions = transactions.where(F.col(\"merchant_abn\") == 62191208634)\n",
    "transactions.show(truncate=False)\n",
    "transactions.summary().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = transactions.groupby(\"order_datetime\").count().sort(\"order_datetime\").to_pandas_on_spark()\n",
    "transactions_df.plot.line(\"order_datetime\", \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_fraud = spark.read.option(\"header\", True).csv(\"../data/tables/consumer_fraud_probability.csv\")\n",
    "consumer_fraud.show()\n",
    "consumer_fraud.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_details = spark.read.parquet(\"../data/tables/consumer_user_details.parquet\")\n",
    "consumer_details.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_fraud = spark.read.option(\"header\", True).csv(\"../data/tables/merchant_fraud_probability.csv\")\n",
    "merchant_fraud.show()\n",
    "merchant_fraud.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_consumer = spark.read.option(\"header\", True).option(\"delimiter\", \"|\").csv(\"../data/tables/tbl_consumer.csv\")\n",
    "tbl_consumer.show(truncate=False)\n",
    "tbl_consumer.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_merchants = spark.read.parquet(\"../data/tables/tbl_merchants.parquet\")\n",
    "tbl_merchants = tbl_merchants.withColumn('tags', F.regexp_replace('tags', r'\\(', r'\\[')) \\\n",
    "    .withColumn('tags', F.lower(F.regexp_replace('tags', r'\\)', r'\\]')))\n",
    "\n",
    "tbl_merchants = tbl_merchants.withColumn('tags1', (F.regexp_extract('tags', r'\\[(\\[[^\\]]*\\])[^\\[]*\\[([^\\]]*)\\][^\\[]*\\[take rate: ([^\\]]*)\\]\\]', idx=1)))\n",
    "tbl_merchants = tbl_merchants.withColumn('tags2', (F.regexp_extract('tags', r'\\[(\\[[^\\]]*\\])[^\\[]*\\[([^\\]]*)\\][^\\[]*\\[take rate: ([^\\]]*)\\]\\]', idx=2)))\n",
    "tbl_merchants = tbl_merchants.withColumn('tags3', (F.regexp_extract('tags', r'\\[(\\[[^\\]]*\\])[^\\[]*\\[([^\\]]*)\\][^\\[]*\\[take rate: ([^\\]]*)\\]\\]', idx=3)).cast(DoubleType()))\n",
    "tbl_merchants.sort('tags3').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_merchants_counts = tbl_merchants.groupby('tags2', 'tags3').count()\n",
    "tbl_merchants_counts.select('tags2', 'tags3', 'count').to_pandas_on_spark().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.abs.gov.au/census/find-census-data/datapacks?release=2021&product=GCP&geography=SA2&header=S\n",
    "TABLES = ['2021Census_G02_AUST_SA2.csv', '2021Census_G04A_AUST_SA2.csv', '2021Census_G04B_AUST_SA2.csv']\n",
    "SELECTED_COLUMNS = ['SA2_CODE_2021', 'Median_age_persons', 'Median_tot_fam_inc_weekly', 'Median_tot_hhd_inc_weekly', 'Average_household_size', 'Tot_M', 'Tot_P', 'Tot_F']\n",
    "\n",
    "census_df = None\n",
    "for table in TABLES:\n",
    "    df = spark.read.options(header=True) \\\n",
    "        .csv(f\"../data/landing/2021_GCP_SA2_for_AUS_short-header/2021 Census GCP Statistical Area 2 for AUS/{table}\")\n",
    "    if census_df is None:\n",
    "        census_df = df\n",
    "    else:\n",
    "        census_df = census_df.join(df, [\n",
    "            census_df.SA2_CODE_2021 == df.SA2_CODE_2021\n",
    "        ]).drop(df.SA2_CODE_2021)\n",
    "    \n",
    "census_df = census_df.select(*SELECTED_COLUMNS)\n",
    "for column in SELECTED_COLUMNS[1:]:\n",
    "    census_df = census_df.withColumn(column, F.col(column).cast(DoubleType()))\n",
    "census_df.show()\n",
    "census_df.summary().show()\n",
    "census_df.write.mode('overwrite').parquet('../data/raw/census2021.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files\n",
    "# Plot choropleth maps for each selected column\n",
    "sa2_df = gpd.read_file('../data/landing/SA2_2021_AUST_SHP_GDA2020')\n",
    "\n",
    "census_df = pd.read_parquet('../data/raw/census2021.parquet')\n",
    "sa2_df = sa2_df.merge(census_df, left_on='SA2_CODE21', right_on='SA2_CODE_2021')\n",
    "\n",
    "sa2_df = sa2_df.dropna()\n",
    "\n",
    "m = folium.Map(location=[-25.2744, 133.7751], zoom_start=4)  # Coordinates and zoom level for Australia\n",
    "# for column in SELECTED_COLUMNS[1:]:\n",
    "folium.Choropleth(\n",
    "    geo_data=sa2_df,\n",
    "    data=sa2_df,\n",
    "    columns=['SA2_CODE21', 'Tot_P'],\n",
    "    key_on='feature.properties.SA2_CODE21',\n",
    "    fill_color='YlGnBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    nan_fill_color='gray',\n",
    "    legend_name='Total Population'\n",
    ").add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
